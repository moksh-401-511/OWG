{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f308326e-3838-4cf6-885a-4acfeb3bd5c3",
   "metadata": {},
   "source": [
    "# Open-Ended Grounding in OCID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18a03c-4e73-4099-a034-d6e3ac3e9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebf7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from third_party.grconvnet import grconvnet\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images path\n",
    "img_id = 6\n",
    "rgb_path = f\"/home/moksh/datasets/captured_images/rgb_images/rgb_image_{img_id}.png\"\n",
    "depth_path = f\"/home/moksh/datasets/captured_images/depth_images/depth_image_{img_id}.npy\"\n",
    "\n",
    "depth_scale = 1000\n",
    "\n",
    "# load images\n",
    "rgb_image = np.asarray(Image.open(rgb_path))\n",
    "depth_image = np.load(depth_path) / depth_scale\n",
    "\n",
    "# show images\n",
    "# Image.fromarray(rgb_image).show()\n",
    "# Image.fromarray(depth_image).show()\n",
    "plt.figure(figsize=(18, 8))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.imshow(rgb_image)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.imshow(depth_image)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraX:\n",
    "    def __init__(self):\n",
    "        self.near = 0.01\n",
    "        self.far = 2.0\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.z = 0\n",
    "\n",
    "camerax = CameraX()\n",
    "checkpoint = \"robotic-grasping/trained-models/jacquard-rgbd-grconvnet3-drop0-ch32/epoch_48_iou_0.93\"\n",
    "grasp_generator = grconvnet.load_grasp_generator(camerax, checkpoint=checkpoint, img_size=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d150f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasps, save_name = grasp_generator.predict_grasp(rgb_image, depth_image, show_output=True, n_grasps=50)\n",
    "print(grasps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c4cb8-69e5-49af-955c-ea6d98ab4b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
